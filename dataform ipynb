import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,r2_score
import numpy as np
from sklearn.ensemble import RandomForestRegressor
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,r2_score
import numpy as np
from sklearn.ensemble import RandomForestRegressor
df.head()
print(df.columns)
# Step 1: Convert Date column to datetime
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")

# Step 2: Extract year, month, day
df["year"] = df["Date"].dt.year
df["month"] = df["Date"].dt.month
df["day"] = df["Date"].dt.day

# Step 3: Create weekend flag (1 = weekend, 0 = weekday)
df["weekend"] = df["Date"].dt.weekday.isin([5, 6]).astype(int)

# Preview result
print(df.head())
print(df.isnull().sum())
  plt.figure(figsize=(10,5))

# Only compute mean of Units Sold
df.groupby('day')['Units Sold'].mean().plot()

plt.title("Average Units Sold by Day of Month")
plt.xlabel("Day of Month")
plt.ylabel("Average Units Sold")
plt.show()
  plt.figure(figsize=(15, 10))

# Filter for year 2022
data = df[df['year'] == 2022].copy()

# Define window size
window_size = 30

# Compute 30-day simple moving average (SMA)
sma = data['Units Sold'].rolling(window=window_size).mean()

# Plot original series
data['Units Sold'].plot(label="Daily Units Sold")

# Plot SMA
sma.plot(label=f"{window_size}-day SMA")

plt.title("Units Sold with 30-day SMA (2022)")
plt.xlabel("Date")
plt.ylabel("Units Sold")
plt.legend()
plt.show()
  plt.subplots(figsize=(12, 5))

# Histogram + KDE
plt.subplot(1, 2, 1)
sns.histplot(df['Units Sold'], kde=True)   # replacement for distplot

# Boxplot
plt.subplot(1, 2, 2)
sns.boxplot(x=df['Units Sold'])

plt.show()
plt.figure(figsize=(10, 10))
corr_matrix = df.corr(numeric_only=True)   # only numeric columns

sns.heatmap(corr_matrix, 
           annot=True,        # show correlation values
           fmt=".2f",         # 2 decimal places
           cmap="coolwarm",   # color gradient
           cbar=True)
plt.show()
#slecting required features
features=['Store ID','Product ID','year','month']
targets='Inventory Level'
X=df[features]
y=df[targets]

  # 6. Split Data into Training and Testing Sets
# ---------------------------------------------
# The dataset is divided into:
# - Training set (80%) → used to train the model
# - Testing set (20%)  → used to evaluate how well the model performs on unseen data

X_train,X_test,y_train,y_test=train_test_split(
    X,y,
    test_size=0.2,     #20% for testing,80% for training
    random_state=42
)
#to print
print("Total rows:",len(X))
print("Training rows:",len(X_train))
print("Testing rows:",len(X_test))
  #Train the model using random forest model
model=RandomForestRegressor(n_estimators=100,random_state=42)
model.fit(X_train,y_train)
  #predict and evaluate
y_pred=model.predict(X_test)
  #evaluation matrics
rmse=np.sqrt(mean_squared_error(y_test,y_pred))
r2=r2_score(y_test,y_pred)
print("rmse",round(rmse,2))
print("r2_score",round(r2,4))
  plt.Figure(figsize=(10,5))
plt.plot(y_test.values[:100],label="Actual",marker="o")
plt.plot(y_pred[:50],label="predicted",marker="X",linestyle="dashed")
plt.title("Actual Vs Predicted demand(first 100 samples)")
plt.xlabel("sample index")
plt.ylabel("demand")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
#prediction
#future_input=pd.DataFrame({
    #'Store ID':[5],
    #'Product ID':[6],
    #'year':[2023],
    #'month':[3]


#})
#future_prediction=model.predict(future_input)
#preds = future_prediction.flatten()  # flatten to 1D array

#print("Predicted stock price:", round(preds[0], 2))
#print("Predicted units sold:", round(preds[1], 2))
#print("Predicted units ordered:", round(preds[2], 2))
#print("Predicted inventory level:", round(preds[3], 2))
